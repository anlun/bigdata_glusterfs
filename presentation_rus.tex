\documentclass{beamer}
\mode<presentation>
{
	%\usetheme{CambridgeUS}
	\usetheme{Madrid}
	\usecolortheme{default}
	\usefonttheme{serif}
}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{cmap}
\usepackage{listings}
\usepackage{lmodern}
\usepackage{color}
\usepackage{minted}

\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks,linkcolor=,urlcolor=links}

\begin{document}
\title
[GlusterFS]
{GlusterFS}
\author
[Подкопаев Антон, Алексеев Антон]
{
Подкопаев Антон, \texttt podkoav239@gmail.com\\
\and
Алексеев Антон, \texttt anton.m.alexeyev@gmail.com
}
\institute[Computer Science Center]{Computer Science Center}
\date [14-03-13]{14 марта 2013}

\begin{frame}[plain]
	\titlepage
\end{frame}

\begin{frame}{Распределенные файловые системы}
	\begin{itemize}
		\item Доступ с многих хостов
		
		\item Инкапсуляция расположения файлов
		% A consistent name space exists encompassing local as well as remote files. The name of a file does not give its location.
		
		\item Реплики и отказоустойчивость
		% That is, when a limited number of nodes in a file system go offline, the system continues to work without any data loss.
		
		\item Параллельный доступ
		% All clients have the same view of the state of the file system. This means that if one process is modifying a file, any other processes on the same system or remote systems that are accessing the files will see the modifications in a coherent manner.
		
		\item Масштабируемость
		% The file system should work well in small environments (1 machine, a dozen machines) and also scale gracefully to huge ones (hundreds through tens of thousands of systems).

		%\item MapReduce
	\end{itemize}
\end{frame}

\begin{frame}{Распределенные файловые системы. Основные компоненты}
	\begin{itemize}
		\item Клиент
		\item Сервер данных
		\item Сервер метаданных
	\end{itemize}
	\pause
	GlusterFS:

	Сервер данных в том числе выполняет и функции сервера метаданных
\end{frame}

\begin{frame}{GlusterFS}
	\begin{itemize}
		% \item Network/cluster filesystem written in user space
		% \item Scale up to petabytes of storage under a single mount point
		\item Сетевая фаловая система, работающая в user space
		\item До петабайт данных в одной точке монтирования
	\end{itemize}
	\begin{figure}[h]
		\centering
		\includegraphics[width=0.7\linewidth]{scheme.png}
	\end{figure}
% GlusterFS is a powerful network/cluster filesystem written in user space which uses FUSE to hook itself with VFS layer.
% GlusterFS takes a layered approach to the file system, where features are added/removed as per the requirement.
% Though GlusterFS is a File System, it uses already tried and tested disk file systems like ext3, ext4, xfs, etc. to store the data.
% It can easily scale up to petabytes of storage which is available to user under a single mount point.
\end{frame}

\begin{frame}{Термины GlusterFS}
	\begin{itemize}
		% \item Brick     % The brick is the storage filesystem that has been assigned to a volume.
		% \item Subvolume % A brick after being processed by at least one translator.
		% \item Volume    % The final share after it passes through all the translators.

		\item Brick           % The brick is the storage filesystem that has been assigned to a volume.
		\item Логический диск % The final share after it passes through all the translators.

		%\item Client
		% The machine which mounts the volume (this may also be a server).
		%\item Server
		% The machine (virtual or bare metal) which hosts the actual filesystem in which data will be stored.

		% \item Translator
		% The brick's first translator (or last, depending on what direction data is flowing) is the storage/posix translator that manages the direct filesystem interface for the rest of the translators.
		% The configuration of translators (since GlusterFS 3.1) is managed through the gluster command line interface (cli), so you don't need to know in what order to graph the translators together.
		% All the translators hooked together to perform a function is called a graph. 		

		% \item Trusted storage pool
		\item Доверенные хранилища
		% Before you can configure a GlusterFS volume, you must create a trusted storage pool consisting of the
		% storage servers that provides bricks to a volume.
		% A storage pool is a trusted network of storage servers. 
	\end{itemize}
\end{frame}

\begin{frame}{Типы логических дисков}
	\begin{itemize}
		\item Распределеные
		\item Реплицируемые
		\item Разделяющие
		\vspace{1cm}
		\item Распределенные разделяющие
		\item Распределенные реплицируемые
		\item Разделяющие реплицируемые
	\end{itemize}
\end{frame}

\begin{frame}{Распределенные логические диски (1)}
	\begin{figure}[h]
		\centering
		\includegraphics[width=0.8\linewidth]{distributed.png}
	\end{figure}
	% \begin{block}{}
		% gluster volume create test-volume server1:/exp1 server2:/exp2
	% \end{block}

	% The server that the files are written to is calculated by hashing the filename.
	% If the filename changes, a pointer file is written to the server that the new hash
	% code would point to, telling the distribute translator which server the file is actually on.
\end{frame}

\begin{frame}{Распределенные логические диски (2)}
	\begin{block}{Плюсы}
		\begin{itemize}
			% \item More servers - better scaling
			\item Больше серверов => выше производительность при параллельном доступе
			% in terms of random file access. As long as clients aren't all retrieving the same file,
			% their access should be spread pretty evenly across all the servers.

			% \item Increasing volume - adding a new server % on-the-fly
			\item Увеличение диска = добавление сервера (можно во время работы) % on-the-fly
		\end{itemize}
	\end{block}
	\begin{block}{Минусы}
		\begin{itemize}
			\item Потеря сервера = потеря данных на нем
			\item Файл не может быть больше размера узла
			\item Смена имени файла => дополнительное время на lookup
		\end{itemize}
	\end{block}
\end{frame}

\begin{frame}{Реплицируемые логические диски}
	\begin{figure}[h]
		\centering
		\includegraphics[width=0.8\linewidth]{replicated.png}
	\end{figure}
	% \begin{block}{}
	% 	gluster volume create test-volume replica 2 server1:/exp1 server2:/exp2
	% \end{block}
\end{frame}

\begin{frame}{Разделяющие логические диски}
	\begin{figure}[h]
		\centering
		\includegraphics[width=0.8\linewidth]{striped.png}
	\end{figure}
	% \begin{block}{}
	% 	gluster volume create test-volume stripe 2 server1:/exp1 server2:/exp2
	% \end{block}
\end{frame}

\begin{frame}{Запуск GlusterFS}
	\inputminted{bash}{sc2}
	\pause
	\inputminted{bash}{sc1}
	\pause
	\inputminted{bash}{sc3}
\end{frame}

\begin{frame}{Производительность GlusterFS}
	asdsa
\end{frame}

\begin{frame}{Links}
	\begin{itemize}
		\item \url{http://www.gluster.org/}
		\item Взрослеем с GlusterFS \url{http://habrahabr.ru/post/140031/}
		\item GlusterFS, опыт новой версии \url{http://habrahabr.ru/post/157029/}
	\end{itemize}
\end{frame}

\end{document}